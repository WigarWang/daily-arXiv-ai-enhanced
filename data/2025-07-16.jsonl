{"id": "2507.10634", "categories": ["eess.SY", "cs.LG", "cs.SY", "eess.SP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.10634", "abs": "https://arxiv.org/abs/2507.10634", "authors": ["Thomas Feys", "Liesbet Van der Perre", "François Rottenberg"], "title": "Learning to Quantize and Precode in Massive MIMO Systems for Energy Reduction: a Graph Neural Network Approach", "comment": null, "summary": "Massive MIMO systems are moving toward increased numbers of radio frequency\nchains, higher carrier frequencies and larger bandwidths. As such,\ndigital-to-analog converters (DACs) are becoming a bottleneck in terms of\nhardware complexity and power consumption. In this work, non-linear precoding\nfor coarsely quantized downlink massive MIMO is studied. Given the NP-hard\nnature of this problem, a graph neural network (GNN) is proposed that directly\noutputs the precoded quantized vector based on the channel matrix and the\nintended transmit symbols. The model is trained in a self-supervised manner, by\ndirectly maximizing the achievable rate. To overcome the non-differentiability\nof the objective function, introduced due to the non-differentiable DAC\nfunctions, a straight-through Gumbel-softmax estimation of the gradient is\nproposed. The proposed method achieves a significant increase in achievable sum\nrate under coarse quantization. For instance, in the single-user case, the\nproposed method can achieve the same sum rate as maximum ratio transmission\n(MRT) by using one-bit DAC's as compared to 3 bits for MRT. This reduces the\nDAC's power consumption by a factor 4-7 and 3 for baseband and RF DACs\nrespectively. This, however, comes at the cost of increased digital signal\nprocessing power consumption. When accounting for this, the reduction in\noverall power consumption holds for a system bandwidth up to 3.5 MHz for\nbaseband DACs, while the RF DACs can maintain a power reduction of 2.9 for\nhigher bandwidths. Notably, indirect effects, which further reduce the power\nconsumption, such as a reduced fronthaul consumption and reduction in other\ncomponents, are not considered in this analysis."}
{"id": "2507.10979", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.10979", "abs": "https://arxiv.org/abs/2507.10979", "authors": ["Mahdieh Zaker", "Amy Nejati", "Abolfazl Lavaei"], "title": "Data-Driven Safety Certificates of Infinite Networks with Unknown Models and Interconnection Topologies", "comment": null, "summary": "Infinite networks are complex interconnected systems comprising a countably\ninfinite number of subsystems, where counting them precisely poses a\nsignificant challenge due to the seemingly endless interconnected nature of the\nnetwork (e.g., counting vehicles on the road). In such scenarios, the presence\nof infinitely many subsystems within the network renders the existing analysis\nframeworks tailored for finite networks inapplicable to infinite ones. This\npaper is concerned with offering a data-driven approach, within a compositional\nframework, for the safety certification of infinite networks with both unknown\nmathematical models and interconnection topologies. Given the immense\ncomputational complexity stemming from the extensive dimension of infinite\nnetworks, our approach capitalizes on the joint dissipativity-type properties\nof subsystems, characterized by storage certificates. We introduce innovative\ncompositional data-driven conditions to construct a barrier certificate for the\ninfinite network leveraging storage certificates of its unknown subsystems\nderived from data, while offering correctness guarantees across the network\nsafety. We demonstrate that our compositional data-driven reasoning eliminates\nthe requirement for checking the traditional dissipativity condition, which\ntypically mandates precise knowledge of the interconnection topology. In\naddition, while existing data-driven literature demonstrates an exponential\ntrend in sample complexity with respect to network size, we showcase that our\ncompositional strategy notably reduces it to a linear scale in terms of the\nnumber of subsystems. We illustrate our data-driven results on two physical\ninfinite networks with unknown models and interconnection topologies."}
{"id": "2507.11021", "categories": ["eess.SY", "cs.GT", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.11021", "abs": "https://arxiv.org/abs/2507.11021", "authors": ["Pau de las Heras Molins", "Eric Roy-Almonacid", "Dong Ho Lee", "Lasse Peters", "David Fridovich-Keil", "Georgios Bakirtzis"], "title": "Approximate solutions to games of ordered preference", "comment": null, "summary": "Autonomous vehicles must balance ranked objectives, such as minimizing travel\ntime, ensuring safety, and coordinating with traffic. Games of ordered\npreference effectively model these interactions but become computationally\nintractable as the time horizon, number of players, or number of preference\nlevels increase. While receding horizon frameworks mitigate long-horizon\nintractability by solving sequential shorter games, often warm-started, they do\nnot resolve the complexity growth inherent in existing methods for solving\ngames of ordered preference. This paper introduces a solution strategy that\navoids excessive complexity growth by approximating solutions using\nlexicographic iterated best response (IBR) in receding horizon, termed\n\"lexicographic IBR over time.\" Lexicographic IBR over time uses past\ninformation to accelerate convergence. We demonstrate through simulated traffic\nscenarios that lexicographic IBR over time efficiently computes\napproximate-optimal solutions for receding horizon games of ordered preference,\nconverging towards generalized Nash equilibria."}
{"id": "2507.11064", "categories": ["eess.SY", "cs.AI", "cs.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2507.11064", "abs": "https://arxiv.org/abs/2507.11064", "authors": ["Sehyun Ryu", "Hyun Jong Yang"], "title": "Standards-Compliant DM-RS Allocation via Temporal Channel Prediction for Massive MIMO Systems", "comment": null, "summary": "Reducing feedback overhead in beyond 5G networks is a critical challenge, as\nthe growing number of antennas in modern massive MIMO systems substantially\nincreases the channel state information (CSI) feedback demand in frequency\ndivision duplex (FDD) systems. To address this, extensive research has focused\non CSI compression and prediction, with neural network-based approaches gaining\nmomentum and being considered for integration into the 3GPP 5G-Advanced\nstandards. While deep learning has been effectively applied to CSI-limited\nbeamforming and handover optimization, reference signal allocation under such\nconstraints remains surprisingly underexplored. To fill this gap, we introduce\nthe concept of channel prediction-based reference signal allocation (CPRS),\nwhich jointly optimizes channel prediction and DM-RS allocation to improve data\nthroughput without requiring CSI feedback. We further propose a\nstandards-compliant ViViT/CNN-based architecture that implements CPRS by\ntreating evolving CSI matrices as sequential image-like data, enabling\nefficient and adaptive transmission in dynamic environments. Simulation results\nusing ray-tracing channel data generated in NVIDIA Sionna validate the proposed\nmethod, showing up to 36.60% throughput improvement over benchmark strategies."}
{"id": "2507.10603", "categories": ["math.OC", "cs.CE"], "pdf": "https://arxiv.org/pdf/2507.10603", "abs": "https://arxiv.org/abs/2507.10603", "authors": ["Kasper Johansson", "Stephen Boyd"], "title": "A Tax-Efficient Model Predictive Control Policy for Retirement Funding", "comment": null, "summary": "The retirement funding problem addresses the question of how to manage a\nretiree's savings to provide her with a constant post-tax inflation adjusted\nconsumption throughout her lifetime. This consists of choosing withdrawals and\ntransfers from and between several accounts with different tax treatments,\ntaking into account basic rules such as required minimum distributions and\nlimits on Roth conversions, additional income, liabilities, taxes, and the\nbequest when the retiree dies. We develop a retirement funding policy in two\nsteps. In the first step, we consider a simplified planning problem in which\nvarious future quantities, such as the retiree's remaining lifetime, future\ninvestment returns, and future inflation, are known. Using a simplified model\nof taxes, we pose this planning problem as a convex optimization problem, where\nwe maximize the bequest subject to providing a constant inflation adjusted\nconsumption target. Since this problem is convex, it can be solved quickly and\nreliably. We leverage this planning method to form a retirement funding policy\nthat determines the actions to take each year, based on information known at\nthat time. Each year the retiree forms a new plan for the future years, using\nthe current account values and life expectancy, and optionally, updated\ninformation such as changes in tax rates or rules. The retiree then carries out\nthe actions from the first year of the current plan. This update-plan-act cycle\nis repeated each year, a general policy called model predictive control (MPC).\nThe MPC retirement policy reacts to the effects of uncertain investment returns\nand inflation, changes in the retiree's expected lifetime or external income\nand liabilities, and changes in tax rules and rates. We demonstrate the\neffectiveness of the MPC retirement policy using Monte Carlo simulation."}
{"id": "2507.10602", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10602", "abs": "https://arxiv.org/abs/2507.10602", "authors": ["Maximilian Stölzle", "T. Konstantin Rusch", "Zach J. Patterson", "Rodrigo Pérez-Dattari", "Francesco Stella", "Josie Hughes", "Cosimo Della Santina", "Daniela Rus"], "title": "Learning to Move in Rhythm: Task-Conditioned Motion Policies with Orbital Stability Guarantees", "comment": "73 pages", "summary": "Learning from demonstration provides a sample-efficient approach to acquiring\ncomplex behaviors, enabling robots to move robustly, compliantly, and with\nfluidity. In this context, Dynamic Motion Primitives offer built - in stability\nand robustness to disturbances but often struggle to capture complex periodic\nbehaviors. Moreover, they are limited in their ability to interpolate between\ndifferent tasks. These shortcomings substantially narrow their applicability,\nexcluding a wide class of practically meaningful tasks such as locomotion and\nrhythmic tool use. In this work, we introduce Orbitally Stable Motion\nPrimitives (OSMPs) - a framework that combines a learned diffeomorphic encoder\nwith a supercritical Hopf bifurcation in latent space, enabling the accurate\nacquisition of periodic motions from demonstrations while ensuring formal\nguarantees of orbital stability and transverse contraction. Furthermore, by\nconditioning the bijective encoder on the task, we enable a single learned\npolicy to represent multiple motion objectives, yielding consistent zero-shot\ngeneralization to unseen motion objectives within the training distribution. We\nvalidate the proposed approach through extensive simulation and real-world\nexperiments across a diverse range of robotic platforms - from collaborative\narms and soft manipulators to a bio-inspired rigid-soft turtle robot -\ndemonstrating its versatility and effectiveness in consistently outperforming\nstate-of-the-art baselines such as diffusion policies, among others."}
{"id": "2507.11113", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.11113", "abs": "https://arxiv.org/abs/2507.11113", "authors": ["Yueyue Xu", "Yuewei Chen", "Lin Wang", "Zhaoyang Cheng", "Xiaoming Hu"], "title": "Optimal Honeypot Ratio and Convergent Fictitious-Play Learning in Signaling Games for CPS Defense", "comment": "14 pages, 8 figures", "summary": "Cyber-Physical Systems (CPSs) are facing a fast-growing wave of attacks. To\nachieve effective proactive defense, this paper models honeypot deployment as a\ngamma-fixed signaling game in which node liveness serves as the only signal and\nnormal-node signal gamma is exogenously fixed. We define the gamma-perfect\nBayesian-Nash equilibrium (gamma-PBNE). Analytical expressions are obtained for\nall gamma-PBNEs, revealing three distinct equilibrium regimes that depend on\nthe priori honeypot ratio. Furthermore, the optimal honeypot ratio and\nsignaling strategy that jointly maximize the network average utility are\nobtained. To capture strategic interaction over time, we develop a\ndiscrete-time fictitious-play algorithm that couples Bayesian belief updates\nwith empirical best responses. We prove that, as long as the honeypot ratio is\nperturbed within a non-degenerate neighbourhood of the optimum, every\nfictitious-play path converges to the defender-optimal gamma-PBNE. Numerical\nresults confirm the effectiveness of the proposed method and demonstrate its\napplicability to CPS defense."}
{"id": "2507.10604", "categories": ["math.OC", "math.PR"], "pdf": "https://arxiv.org/pdf/2507.10604", "abs": "https://arxiv.org/abs/2507.10604", "authors": ["Emma Hubert", "Dimitrios Lolas", "Ronnie Sircar"], "title": "A Mean Field Game for Capacity Expansion Modeling", "comment": null, "summary": "This paper studies the optimal investment behavior of renewable electricity\nproducers in a competitive market, where both prices and installation costs are\ninfluenced by aggregate industry activity. We model the resulting crowding\neffects using a mean field game framework, capturing the strategic interactions\namong a continuum of heterogeneous producers. The equilibrium dynamics are\ncharacterized via a coupled system of Hamilton-Jacobi-Bellman and Fokker-Planck\nequations, which describe the value function of a representative producer and\nthe evolution of the distribution of installed capacities over time. We analyze\nboth deterministic and stochastic versions of the model, providing analytical\ninsights in tractable cases and developing numerical methods to approximate the\ngeneral solution. Simulation results illustrate how aggregate investment\nresponds to changing market conditions, cost structures, and exogenous\nproductivity shocks."}
{"id": "2507.10672", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.10672", "abs": "https://arxiv.org/abs/2507.10672", "authors": ["Muhayy Ud Din", "Waseem Akram", "Lyes Saad Saoud", "Jan Rosell", "Irfan Hussain"], "title": "Vision Language Action Models in Robotic Manipulation: A Systematic Review", "comment": "submitted to annual review in control", "summary": "Vision Language Action (VLA) models represent a transformative shift in\nrobotics, with the aim of unifying visual perception, natural language\nunderstanding, and embodied control within a single learning framework. This\nreview presents a comprehensive and forward-looking synthesis of the VLA\nparadigm, with a particular emphasis on robotic manipulation and\ninstruction-driven autonomy. We comprehensively analyze 102 VLA models, 26\nfoundational datasets, and 12 simulation platforms that collectively shape the\ndevelopment and evaluation of VLAs models. These models are categorized into\nkey architectural paradigms, each reflecting distinct strategies for\nintegrating vision, language, and control in robotic systems. Foundational\ndatasets are evaluated using a novel criterion based on task complexity,\nvariety of modalities, and dataset scale, allowing a comparative analysis of\ntheir suitability for generalist policy learning. We introduce a\ntwo-dimensional characterization framework that organizes these datasets based\non semantic richness and multimodal alignment, showing underexplored regions in\nthe current data landscape. Simulation environments are evaluated for their\neffectiveness in generating large-scale data, as well as their ability to\nfacilitate transfer from simulation to real-world settings and the variety of\nsupported tasks. Using both academic and industrial contributions, we recognize\nongoing challenges and outline strategic directions such as scalable\npretraining protocols, modular architectural design, and robust multimodal\nalignment strategies. This review serves as both a technical reference and a\nconceptual roadmap for advancing embodiment and robotic control, providing\ninsights that span from dataset generation to real world deployment of\ngeneralist robotic agents."}
{"id": "2507.11240", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.11240", "abs": "https://arxiv.org/abs/2507.11240", "authors": ["Mohamad Al Ahdab", "John Leth", "Zheng-Hua Tan"], "title": "Optimal Sensor Scheduling and Selection for Continuous-Discrete Kalman Filtering with Auxiliary Dynamics", "comment": "Accepted to ICML 2025", "summary": "We study the Continuous-Discrete Kalman Filter (CD-KF) for State-Space Models\n(SSMs) where continuous-time dynamics are observed via multiple sensors with\ndiscrete, irregularly timed measurements. Our focus extends to scenarios in\nwhich the measurement process is coupled with the states of an auxiliary SSM.\nFor instance, higher measurement rates may increase energy consumption or heat\ngeneration, while a sensor's accuracy can depend on its own spatial trajectory\nor that of the measured target. Each sensor thus carries distinct costs and\nconstraints associated with its measurement rate and additional constraints and\ncosts on the auxiliary state. We model measurement occurrences as independent\nPoisson processes with sensor-specific rates and derive an upper bound on the\nmean posterior covariance matrix of the CD-KF along the mean auxiliary state.\nThe bound is continuously differentiable with respect to the measurement rates,\nwhich enables efficient gradient-based optimization. Exploiting this bound, we\npropose a finite-horizon optimal control framework to optimize measurement\nrates and auxiliary-state dynamics jointly. We further introduce a\ndeterministic method for scheduling measurement times from the optimized rates.\nEmpirical results in state-space filtering and dynamic temporal Gaussian\nprocess regression demonstrate that our approach achieves improved trade-offs\nbetween resource usage and estimation accuracy."}
{"id": "2507.10735", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.10735", "abs": "https://arxiv.org/abs/2507.10735", "authors": ["Jonathan Yu-Meng Li", "Tiantian Mao", "Reza Valimoradi"], "title": "Reconciling Risk-Aversion Paradoxes in the Distribution-Free Newsvendor Problem: Scarf's Rule Meets Dual Utility", "comment": null, "summary": "How should a risk-averse newsvendor order optimally under distributional\nambiguity? Attempts to extend Scarf's celebrated distribution-free ordering\nrule using risk measures have led to conflicting prescriptions: CVaR-based\nmodels invariably recommend ordering less as risk aversion increases, while\nmean-standard deviation models -- paradoxically -- suggest ordering more,\nparticularly when ordering costs are high. We resolve this behavioral paradox\nthrough a coherent generalization of Scarf's distribution-free framework,\nmodeling risk aversion via distortion functionals from dual utility theory.\nDespite the generality of this class, we derive closed-form optimal ordering\nrules for any coherent risk preference. These rules uncover a consistent\nbehavioral principle: a more risk-averse newsvendor may rationally order more\nwhen overstocking is inexpensive (i.e., when the cost-to-price ratio is low),\nbut will always order less when ordering is costly. Our framework offers a more\nnuanced, managerially intuitive, and behaviorally coherent understanding of\nrisk-averse inventory decisions. It exposes the limitations of non-coherent\nmodels, delivers interpretable and easy-to-compute ordering rules grounded in\ncoherent preferences, and unifies prior work under a single, tractable\napproach. We further extend the results to multi-product settings with\narbitrary demand dependencies, showing that optimal order quantities remain\nseparable and can be obtained by solving single-product problems independently."}
{"id": "2507.10694", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.10694", "abs": "https://arxiv.org/abs/2507.10694", "authors": ["Francesco Fuentes", "Serigne Diagne", "Zachary Kingston", "Laura H. Blumenschein"], "title": "Exteroception through Proprioception Sensing through Improved Contact Modeling for Soft Growing Robots", "comment": "22 pages, 21 figures, submitted to journal for potential publication", "summary": "Passive deformation due to compliance is a commonly used benefit of soft\nrobots, providing opportunities to achieve robust actuation with few active\ndegrees of freedom. Soft growing robots in particular have shown promise in\nnavigation of unstructured environments due to their passive deformation. If\ntheir collisions and subsequent deformations can be better understood, soft\nrobots could be used to understand the structure of the environment from direct\ntactile measurements. In this work, we propose the use of soft growing robots\nas mapping and exploration tools. We do this by first characterizing collision\nbehavior during discrete turns, then leveraging this model to develop a\ngeometry-based simulator that models robot trajectories in 2D environments.\nFinally, we demonstrate the model and simulator validity by mapping unknown\nenvironments using Monte Carlo sampling to estimate the optimal next deployment\ngiven current knowledge. Over both uniform and non-uniform environments, this\nselection method rapidly approaches ideal actions, showing the potential for\nsoft growing robots in unstructured environment exploration and mapping."}
{"id": "2507.11377", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.11377", "abs": "https://arxiv.org/abs/2507.11377", "authors": ["Philipp Wiesner", "Odej Kao"], "title": "Moving Beyond Marginal Carbon Intensity: A Poor Metric for Both Carbon Accounting and Grid Flexibility", "comment": "Presented at the Workshop on Measurements, Modeling, and Metrics for\n  Carbon-Aware Computing (CarbonMetrics) @ ACM SIGMETRICS '25", "summary": "Marginal Carbon Intensity (MCI) has been promoted as an effective metric for\ncarbon-aware computing. Although it is already considered as impractical for\ncarbon accounting purposes, many still view it as valuable when optimizing for\ngrid flexibility by incentivizing electricity usage during curtailment periods.\nIn this statement paper, we argue that MCI is neither reliable nor actionable\nfor either purpose. We outline its fundamental limitations, including\nnon-observability, reliance on opaque predictive models, and the lack of\nverifiability. Moreover, MCI fails to reflect curtailment caused by high-carbon\nsources and offers no insight into the quantity of available excess power. We\nadvocate moving beyond MCI and instead call for research on more actionable\nmetrics, such as direct reporting of excess power, explicit modeling of energy\nstorage and grid stability, and integration with emerging granular renewable\nenergy certificate markets."}
{"id": "2507.10901", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.10901", "abs": "https://arxiv.org/abs/2507.10901", "authors": ["Tommaso Giovannelli", "Jingfu Tan", "Luis Nunes Vicente"], "title": "Non-smooth stochastic gradient descent using smoothing functions", "comment": null, "summary": "In this paper, we address stochastic optimization problems involving a\ncomposition of a non-smooth outer function and a smooth inner function, a\nformulation frequently encountered in machine learning and operations research.\nTo deal with the non-differentiability of the outer function, we approximate\nthe original non-smooth function using smoothing functions, which are\ncontinuously differentiable and approach the original function as a smoothing\nparameter goes to zero (at the price of increasingly higher Lipschitz\nconstants). The proposed smoothing stochastic gradient method iteratively\ndrives the smoothing parameter to zero at a designated rate. We establish\nconvergence guarantees under strongly convex, convex, and nonconvex settings,\nproving convergence rates that match known results for non-smooth stochastic\ncompositional optimization. In particular, for convex objectives, smoothing\nstochastic gradient achieves a 1/T^(1/4) rate in terms of the number of\nstochastic gradient evaluations. We further show how general compositional and\nfinite-sum compositional problems (widely used frameworks in large-scale\nmachine learning and risk-averse optimization) fit the assumptions needed for\nthe rates (unbiased gradient estimates, bounded second moments, and accurate\nsmoothing errors). We present preliminary numerical results indicating that\nsmoothing stochastic gradient descent can be competitive for certain classes of\nproblems."}
{"id": "2507.10749", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.10749", "abs": "https://arxiv.org/abs/2507.10749", "authors": ["Benjamin Stoler", "Juliet Yang", "Jonathan Francis", "Jean Oh"], "title": "RCG: Safety-Critical Scenario Generation for Robust Autonomous Driving via Real-World Crash Grounding", "comment": null, "summary": "Safety-critical scenarios are essential for training and evaluating\nautonomous driving (AD) systems, yet remain extremely rare in real-world\ndriving datasets. To address this, we propose Real-world Crash Grounding (RCG),\na scenario generation framework that integrates crash-informed semantics into\nadversarial perturbation pipelines. We construct a safety-aware behavior\nrepresentation through contrastive pre-training on large-scale driving logs,\nfollowed by fine-tuning on a small, crash-rich dataset with approximate\ntrajectory annotations extracted from video. This embedding captures semantic\nstructure aligned with real-world accident behaviors and supports selection of\nadversary trajectories that are both high-risk and behaviorally realistic. We\nincorporate the resulting selection mechanism into two prior scenario\ngeneration pipelines, replacing their handcrafted scoring objectives with an\nembedding-based criterion. Experimental results show that ego agents trained\nagainst these generated scenarios achieve consistently higher downstream\nsuccess rates, with an average improvement of 9.2% across seven evaluation\nsettings. Qualitative and quantitative analyses further demonstrate that our\napproach produces more plausible and nuanced adversary behaviors, enabling more\neffective and realistic stress testing of AD systems. Code and tools will be\nreleased publicly."}
{"id": "2507.11392", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2507.11392", "abs": "https://arxiv.org/abs/2507.11392", "authors": ["Rahel Rickenbach", "Amon Lahr", "Melanie N. Zeilinger"], "title": "Inverse Optimal Control with Constraint Relaxation", "comment": null, "summary": "Inverse optimal control (IOC) is a promising paradigm for learning and\nmimicking optimal control strategies from capable demonstrators, or gaining a\ndeeper understanding of their intentions, by estimating an unknown objective\nfunction from one or more corresponding optimal control sequences. When\ncomputing estimates from demonstrations in environments with safety-preserving\ninequality constraints, acknowledging their presence in the chosen IOC method\nis crucial given their strong influence on the final control strategy. However,\nsolution strategies capable of considering inequality constraints, such as the\ninverse Karush-Kuhn-Tucker approach, rely on their correct activation and\nfulfillment; a restrictive assumption when dealing with noisy demonstrations.\nTo overcome this problem, we leverage the concept of exact penalty functions\nfor IOC and show preservation of estimation accuracy. Considering noisy\ndemonstrations, we then illustrate how the usage of penalty functions reduces\nthe number of unknown variables and how their approximations enhance the\nestimation method's capacity to account for wrong constraint activations within\na polytopic-constrained environment. The proposed method is evaluated for three\nsystems in simulation, outperforming traditional relaxation approaches for\nnoisy demonstrations."}
{"id": "2507.11058", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.11058", "abs": "https://arxiv.org/abs/2507.11058", "authors": ["Jasarat Gasimov", "Nazim Mahmudov"], "title": "On the optimality conditions for a fractional diffusive equation with a nonlocal term", "comment": null, "summary": "We study a bilinear OCP for an evolution equation governed by the fractional\nLaplacian of order $0 < s < 1$, incorporating a nonlocal time component modeled\nby an integral kernel. After establishing well-posedness of the problem, we\nanalyze the properties of the control-to-state operator. We prove the existence\nof at least one optimal control and derive both first-order and second-order\noptimality conditions, which ensure local uniqueness. Under further\nassumptions, we also demonstrate that global uniqueness of the optimal control\ncan be achieved."}
{"id": "2507.10776", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.10776", "abs": "https://arxiv.org/abs/2507.10776", "authors": ["Howard H. Qian", "Yiting Chen", "Gaotian Wang", "Podshara Chanrungmaneekul", "Kaiyu Hang"], "title": "rt-RISeg: Real-Time Model-Free Robot Interactive Segmentation for Active Instance-Level Object Understanding", "comment": "8 pages, IROS 2025, Interactive Perception, Segmentation, Robotics,\n  Computer Vision", "summary": "Successful execution of dexterous robotic manipulation tasks in new\nenvironments, such as grasping, depends on the ability to proficiently segment\nunseen objects from the background and other objects. Previous works in unseen\nobject instance segmentation (UOIS) train models on large-scale datasets, which\noften leads to overfitting on static visual features. This dependency results\nin poor generalization performance when confronted with out-of-distribution\nscenarios. To address this limitation, we rethink the task of UOIS based on the\nprinciple that vision is inherently interactive and occurs over time. We\npropose a novel real-time interactive perception framework, rt-RISeg, that\ncontinuously segments unseen objects by robot interactions and analysis of a\ndesigned body frame-invariant feature (BFIF). We demonstrate that the relative\nrotational and linear velocities of randomly sampled body frames, resulting\nfrom selected robot interactions, can be used to identify objects without any\nlearned segmentation model. This fully self-contained segmentation pipeline\ngenerates and updates object segmentation masks throughout each robot\ninteraction without the need to wait for an action to finish. We showcase the\neffectiveness of our proposed interactive perception method by achieving an\naverage object segmentation accuracy rate 27.5% greater than state-of-the-art\nUOIS methods. Furthermore, although rt-RISeg is a standalone framework, we show\nthat the autonomously generated segmentation masks can be used as prompts to\nvision foundation models for significantly improved performance."}
{"id": "2507.11420", "categories": ["eess.SY", "cs.SY", "93C40", "I.2.8"], "pdf": "https://arxiv.org/pdf/2507.11420", "abs": "https://arxiv.org/abs/2507.11420", "authors": ["Mingcong Li"], "title": "A Risk-Aware Adaptive Robust MPC with Learned Uncertainty Quantification", "comment": "17 pages, 10 figures", "summary": "Solving chance-constrained optimal control problems for systems subject to\nnon-stationary uncertainties is a significant challenge.Conventional robust\nmodel predictive control (MPC) often yields excessive conservatism by relying\non static worst-case assumptions, while standard stochastic MPC methods\nstruggle when underlying uncertainty distributions are unknown a priori.This\narticle presents a Risk-Aware Adaptive Robust MPC (RAAR-MPC) framework,a\nhierarchical architecture that systematically orchestrates a novel synthesis of\nproactive, learning-based risk assessment and reactive risk regulation. The\nframework employs a medium-frequency risk assessment engine, which leverages\nGaussian process regression and active learning, to construct a tight,\ndata-driven characterization of the prediction error set from operational\ndata.Concurrently, a low-timescale outer loop implements a self-correcting\nupdate law for an adaptive safety margin to precisely regulate the empirical\nrisk and compensate for unmodeled dynamics.This dual-timescale adaptation\nenables the system to rigorously satisfy chance constraints with a user-defined\nprobability, while minimizing the conservatism inherent in traditional\napproaches.We formally establish that the interplay between these adaptive\ncomponents guarantees recursive feasibility and ensures the closed-loop system\nsatisfies the chance constraints up to a user-defined risk level with high\nprobability.Numerical experiments on a benchmark DC-DC converter under\nnon-stationary parametric uncertainties demonstrate that our framework\nprecisely achieves the target risk level, resulting in a significantly lower\naverage cost compared to state-of-the-art robust and stochastic MPC strategies."}
{"id": "2507.11095", "categories": ["math.OC", "cs.IT", "cs.NA", "math.DS", "math.HO", "math.IT", "math.NA"], "pdf": "https://arxiv.org/pdf/2507.11095", "abs": "https://arxiv.org/abs/2507.11095", "authors": ["Alexander Stotsky"], "title": "Performance Enhancement of the Recursive Least Squares Algorithms with Rank Two Updates", "comment": "7pages, 2 figures", "summary": "New recursive least squares algorithms with rank two updates (RLSR2) that\ninclude both exponential and instantaneous forgetting (implemented via a proper\nchoice of the forgetting factor and the window size) are introduced and\nsystematically associated in this report with well-known RLS algorithms with\nrank one updates. Moreover, new properties (which can be used for further\nperformance improvement) of the recursive algorithms associated with the\nconvergence of the inverse of information matrix and parameter vector are\nestablished in this report. The performance of new algorithms is examined in\nthe problem of estimation of the grid events in the presence of significant\nharmonic emissions."}
{"id": "2507.10814", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.10814", "abs": "https://arxiv.org/abs/2507.10814", "authors": ["Huiyi Wang", "Fahim Shahriar", "Alireza Azimi", "Gautham Vasan", "Rupam Mahmood", "Colin Bellinger"], "title": "Versatile and Generalizable Manipulation via Goal-Conditioned Reinforcement Learning with Grounded Object Detection", "comment": "8 pages, 4 figures, 3 tables", "summary": "General-purpose robotic manipulation, including reach and grasp, is essential\nfor deployment into households and workspaces involving diverse and evolving\ntasks. Recent advances propose using large pre-trained models, such as Large\nLanguage Models and object detectors, to boost robotic perception in\nreinforcement learning. These models, trained on large datasets via\nself-supervised learning, can process text prompts and identify diverse objects\nin scenes, an invaluable skill in RL where learning object interaction is\nresource-intensive. This study demonstrates how to integrate such models into\nGoal-Conditioned Reinforcement Learning to enable general and versatile robotic\nreach and grasp capabilities. We use a pre-trained object detection model to\nenable the agent to identify the object from a text prompt and generate a mask\nfor goal conditioning. Mask-based goal conditioning provides object-agnostic\ncues, improving feature sharing and generalization. The effectiveness of the\nproposed framework is demonstrated in a simulated reach-and-grasp task, where\nthe mask-based goal conditioning consistently maintains a $\\sim$90\\% success\nrate in grasping both in and out-of-distribution objects, while also ensuring\nfaster convergence to higher returns."}
{"id": "2507.10968", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.10968", "abs": "https://arxiv.org/abs/2507.10968", "authors": ["Toktam Mohammadnejad", "Jovin D'sa", "Behdad Chalaki", "Hossein Nourkhiz Mahjoub", "Ehsan Moradi-Pari"], "title": "SMART-Merge Planner: A Safe Merging and Real-Time Motion Planner for Autonomous Highway On-Ramp Merging", "comment": "Accepted at IEEE ITSC 2025", "summary": "Merging onto a highway is a complex driving task that requires identifying a\nsafe gap, adjusting speed, often interactions to create a merging gap, and\ncompleting the merge maneuver within a limited time window while maintaining\nsafety and driving comfort. In this paper, we introduce a Safe Merging and\nReal-Time Merge (SMART-Merge) planner, a lattice-based motion planner designed\nto facilitate safe and comfortable forced merging. By deliberately adapting\ncost terms to the unique challenges of forced merging and introducing a desired\nspeed heuristic, SMART-Merge planner enables the ego vehicle to merge\nsuccessfully while minimizing the merge time. We verify the efficiency and\neffectiveness of the proposed merge planner through high-fidelity CarMaker\nsimulations on hundreds of highway merge scenarios. Our proposed planner\nachieves the success rate of 100% as well as completes the merge maneuver in\nthe shortest amount of time compared with the baselines, demonstrating our\nplanner's capability to handle complex forced merge tasks and provide a\nreliable and robust solution for autonomous highway merge. The simulation\nresult videos are available at\nhttps://sites.google.com/view/smart-merge-planner/home."}
{"id": "2507.11106", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.11106", "abs": "https://arxiv.org/abs/2507.11106", "authors": ["Víctor Blanco", "Inmaculada Espejo", "Raúl Páez", "Antonio M. Rodríguez-Chía"], "title": "A Mathematical Optimization Approach to Multisphere Support Vector Data Description", "comment": "18 pages, 5 figures, 3 tables", "summary": "We present a novel mathematical optimization framework for outlier detection\nin multimodal datasets, extending Support Vector Data Description approaches.\nWe provide a primal formulation, in the shape of a Mixed Integer Second Order\nCone model, that constructs Euclidean hyperspheres to identify anomalous\nobservations. Building on this, we develop a dual model that enables the\napplication of the kernel trick, thus allowing for the detection of outliers\nwithin complex, non-linear data structures. An extensive computational study\ndemonstrates the effectiveness of our exact method, showing clear advantages\nover existing heuristic techniques in terms of accuracy and robustness."}
{"id": "2507.10878", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.10878", "abs": "https://arxiv.org/abs/2507.10878", "authors": ["Savva Morozov", "Tobia Marcucci", "Bernhard Paus Graesdal", "Alexandre Amice", "Pablo A. Parrilo", "Russ Tedrake"], "title": "Mixed Discrete and Continuous Planning using Shortest Walks in Graphs of Convex Sets", "comment": "10 pages", "summary": "We study the Shortest-Walk Problem (SWP) in a Graph of Convex Sets (GCS). A\nGCS is a graph where each vertex is paired with a convex program, and each edge\ncouples adjacent programs via additional costs and constraints. A walk in a GCS\nis a sequence of vertices connected by edges, where vertices may be repeated.\nThe length of a walk is given by the cumulative optimal value of the\ncorresponding convex programs. To solve the SWP in GCS, we first synthesize a\npiecewise-quadratic lower bound on the problem's cost-to-go function using\nsemidefinite programming. Then we use this lower bound to guide an\nincremental-search algorithm that yields an approximate shortest walk. We show\nthat the SWP in GCS is a natural language for many mixed discrete-continuous\nplanning problems in robotics, unifying problems that typically require\nspecialized solutions while delivering high performance and computational\nefficiency. We demonstrate this through experiments in collision-free motion\nplanning, skill chaining, and optimal control of hybrid systems."}
{"id": "2507.11211", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.11211", "abs": "https://arxiv.org/abs/2507.11211", "authors": ["Chen Cai", "Ernesto Dickel Saraiva", "Ya-jun Pan", "Steven Liu"], "title": "MPC-based Coarse-to-Fine Motion Planning for Robotic Object Transportation in Cluttered Environments", "comment": "10 pages, 5 figures, submitted to IEEE Robotics and Automation\n  Letters (RA-L)", "summary": "This letter presents a novel coarse-to-fine motion planning framework for\nrobotic manipulation in cluttered, unmodeled environments. The system\nintegrates a dual-camera perception setup with a B-spline-based model\npredictive control (MPC) scheme. Initially, the planner generates feasible\nglobal trajectories from partial and uncertain observations. As new visual data\nare incrementally fused, both the environment model and motion planning are\nprogressively refined. A vision-based cost function promotes target-driven\nexploration, while a refined kernel-perceptron collision detector enables\nefficient constraint updates for real-time planning. The framework accommodates\nclosed-chain kinematics and supports dynamic replanning. Experiments on a\nmulti-arm platform validate its robustness and adaptability under uncertainties\nand clutter."}
{"id": "2507.11253", "categories": ["math.OC", "cs.NA", "math.NA", "49J52, 49J53, 90C31"], "pdf": "https://arxiv.org/pdf/2507.11253", "abs": "https://arxiv.org/abs/2507.11253", "authors": ["Boris S. Mordukhovich", "Peipei Tang", "Chengjing Wang"], "title": "Second-Order Characterizations of Tilt Stability in Composite Optimization", "comment": "32 pages", "summary": "Tilt stability is a fundamental concept of variational analysis and\noptimization that plays a pivotal role in both theoretical issues and numerical\ncomputations. This paper investigates tilt stability of local minimizers for a\ngeneral class of composite optimization problems in finite dimensions, where\nextended-real-valued objectives are compositions of parabolically regular and\nsmooth functions. Under the weakest metric subregularity constraint\nqualification and other verifiable conditions, we establish unified\nneighborhood and pointbased characterizations of tilt stability via\nsecond-order generalized differentiation. The obtained results provide a\nrigorous theoretical foundation for further developments on variational\nstability and numerical algorithms of optimization and related topics."}
{"id": "2507.10899", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.10899", "abs": "https://arxiv.org/abs/2507.10899", "authors": ["Wang Zhicheng", "Satoshi Yagi", "Satoshi Yamamori", "Jun Morimoto"], "title": "Object-Centric Mobile Manipulation through SAM2-Guided Perception and Imitation Learning", "comment": null, "summary": "Imitation learning for mobile manipulation is a key challenge in the field of\nrobotic manipulation. However, current mobile manipulation frameworks typically\ndecouple navigation and manipulation, executing manipulation only after\nreaching a certain location. This can lead to performance degradation when\nnavigation is imprecise, especially due to misalignment in approach angles. To\nenable a mobile manipulator to perform the same task from diverse orientations,\nan essential capability for building general-purpose robotic models, we propose\nan object-centric method based on SAM2, a foundation model towards solving\npromptable visual segmentation in images, which incorporates manipulation\norientation information into our model. Our approach enables consistent\nunderstanding of the same task from different orientations. We deploy the model\non a custom-built mobile manipulator and evaluate it on a pick-and-place task\nunder varied orientation angles. Compared to Action Chunking Transformer, our\nmodel maintains superior generalization when trained with demonstrations from\nvaried approach angles. This work significantly enhances the generalization and\nrobustness of imitation learning-based mobile manipulation systems."}
{"id": "2507.11283", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.11283", "abs": "https://arxiv.org/abs/2507.11283", "authors": ["Weiyi Liu", "Jingzehua Xu", "Guanwen Xie", "Yi Li"], "title": "Ocean Diviner: A Diffusion-Augmented Reinforcement Learning for AUV Robust Control in the Underwater Tasks", "comment": null, "summary": "This paper presents a diffusion-augmented reinforcement learning (RL)\napproach for robust autonomous underwater vehicle (AUV) control, addressing key\nchallenges in underwater trajectory planning and dynamic environment\nadaptation. The proposed method integrates three core innovations: (1) A\ndiffusion-based trajectory generation framework that produces physically\nfeasible multi-step trajectories, enhanced by a high-dimensional state encoding\nmechanism combining current observations with historical states and actions\nthrough a novel diffusion U-Net architecture, significantly improving\nlong-horizon planning. (2) A sample-efficient hybrid learning architecture that\nsynergizes diffusion-guided exploration with RL policy optimization, where the\ndiffusion model generates diverse candidate actions and the RL critic selects\noptimal actions, achieving higher exploration efficiency and policy stability\nin dynamic underwater environments. Extensive simulation experiments validating\nthe method's superior robustness and flexibility, outperforms conventional\ncontrol methods in challenging marine conditions, offering enhanced\nadaptability and reliability for AUV operations in the underwater tasks."}
{"id": "2507.11350", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.11350", "abs": "https://arxiv.org/abs/2507.11350", "authors": ["Jun-ya Gotoh", "Michael Jong Kim", "Andrew E. B. Lim"], "title": "Distributionally Robust Optimization is a Multi-Objective Problem", "comment": null, "summary": "Distributionally Robust Optimization (DRO) is a worst-case approach to\ndecision making when there is model uncertainty. Though formulated as a\nsingle-objective problem, we show that it is intrinsically multi-objective in\nthat DRO solutions map out a near-Pareto-optimal frontier between expected cost\nand a measure of robustness called worst-case sensitivity (WCS). We take this\nas the starting point and explore robust decision making through a\nmulti-objective lens. We show that WCS is a measure of spread and derive WCS\nfor a collection of uncertainty sets commonly used in DRO. These sensitivity\nmeasures identify the errors against which the nominal expected cost is most\nvulnerable and the uncertainty set for the worst-case problem that most\neffectively mitigates it. The associated mean-sensitivity frontier is used to\nselect its size. The multi-objective perspective provides a quantitative\nmeasure of robustness and a sensitivity-based approach to addressing important\nconceptual gaps in DRO -- how to choose the family and size of uncertainty sets\nfor a given cost distribution, and how this affects the solution."}
{"id": "2507.10914", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.10914", "abs": "https://arxiv.org/abs/2507.10914", "authors": ["James A. Preiss", "Fengze Xie", "Yiheng Lin", "Adam Wierman", "Yisong Yue"], "title": "Fast Non-Episodic Adaptive Tuning of Robot Controllers with Online Policy Optimization", "comment": "11 pages, 9 figures", "summary": "We study online algorithms to tune the parameters of a robot controller in a\nsetting where the dynamics, policy class, and optimality objective are all\ntime-varying. The system follows a single trajectory without episodes or state\nresets, and the time-varying information is not known in advance. Focusing on\nnonlinear geometric quadrotor controllers as a test case, we propose a\npractical implementation of a single-trajectory model-based online policy\noptimization algorithm, M-GAPS,along with reparameterizations of the quadrotor\nstate space and policy class to improve the optimization landscape. In hardware\nexperiments,we compare to model-based and model-free baselines that impose\nartificial episodes. We show that M-GAPS finds near-optimal parameters more\nquickly, especially when the episode length is not favorable. We also show that\nM-GAPS rapidly adapts to heavy unmodeled wind and payload disturbances, and\nachieves similar strong improvement on a 1:6-scale Ackermann-steered car. Our\nresults demonstrate the hardware practicality of this emerging class of online\npolicy optimization that offers significantly more flexibility than classic\nadaptive control, while being more stable and data-efficient than model-free\nreinforcement learning."}
{"id": "2507.11350", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.11350", "abs": "https://arxiv.org/abs/2507.11350", "authors": ["Jun-ya Gotoh", "Michael Jong Kim", "Andrew E. B. Lim"], "title": "Distributionally Robust Optimization is a Multi-Objective Problem", "comment": null, "summary": "Distributionally Robust Optimization (DRO) is a worst-case approach to\ndecision making when there is model uncertainty. Though formulated as a\nsingle-objective problem, we show that it is intrinsically multi-objective in\nthat DRO solutions map out a near-Pareto-optimal frontier between expected cost\nand a measure of robustness called worst-case sensitivity (WCS). We take this\nas the starting point and explore robust decision making through a\nmulti-objective lens. We show that WCS is a measure of spread and derive WCS\nfor a collection of uncertainty sets commonly used in DRO. These sensitivity\nmeasures identify the errors against which the nominal expected cost is most\nvulnerable and the uncertainty set for the worst-case problem that most\neffectively mitigates it. The associated mean-sensitivity frontier is used to\nselect its size. The multi-objective perspective provides a quantitative\nmeasure of robustness and a sensitivity-based approach to addressing important\nconceptual gaps in DRO -- how to choose the family and size of uncertainty sets\nfor a given cost distribution, and how this affects the solution."}
{"id": "2507.11461", "categories": ["math.OC", "cs.CV", "65K10, 65J22, 94A08, 47N10"], "pdf": "https://arxiv.org/pdf/2507.11461", "abs": "https://arxiv.org/abs/2507.11461", "authors": ["Christian Daniele", "Silvia Villa", "Samuel Vaiter", "Luca Calatroni"], "title": "Deep Equilibrium models for Poisson Imaging Inverse problems via Mirror Descent", "comment": null, "summary": "Deep Equilibrium Models (DEQs) are implicit neural networks with fixed\npoints, which have recently gained attention for learning image regularization\nfunctionals, particularly in settings involving Gaussian fidelities, where\nassumptions on the forward operator ensure contractiveness of standard\n(proximal) Gradient Descent operators. In this work, we extend the application\nof DEQs to Poisson inverse problems, where the data fidelity term is more\nappropriately modeled by the Kullback-Leibler divergence. To this end, we\nintroduce a novel DEQ formulation based on Mirror Descent defined in terms of a\ntailored non-Euclidean geometry that naturally adapts with the structure of the\ndata term. This enables the learning of neural regularizers within a principled\ntraining framework. We derive sufficient conditions to guarantee the\nconvergence of the learned reconstruction scheme and propose computational\nstrategies that enable both efficient training and fully parameter-free\ninference. Numerical experiments show that our method outperforms traditional\nmodel-based approaches and it is comparable to the performance of Bregman\nPlug-and-Play methods, while mitigating their typical drawbacks - namely,\nsensitivity to initialization and careful tuning of hyperparameters. The code\nis publicly available at https://github.com/christiandaniele/DEQ-MD."}
{"id": "2507.10950", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.10950", "abs": "https://arxiv.org/abs/2507.10950", "authors": ["Zhiwei Wu", "Jiahao Luo", "Siyi Wei", "Jinhui Zhang"], "title": "Unified Modeling and Structural Optimization of Multi-magnet Embedded Soft Continuum Robots for Enhanced Kinematic Performances", "comment": null, "summary": "This paper presents a unified modeling and optimization framework to enhance\nthe kinematic performance of multi-magnet embedded soft continuum robots\n(MeSCRs). To this end, we establish a differentiable system formulation based\non an extended pseudo-rigid-body model. This formulation enables analysis of\nthe equilibrium well-posedness and the geometry of the induced configuration\nunder magnetic actuation. In particular, we show that the maximum controllable\ndegrees of freedom of a MeSCR equal twice the number of embedded magnets. We\nsubsequently develop a structural optimization framework based on differential\ngeometry that links classical kinematic measures (e.g., manipulability and\ndexterity) to the configuration of embedded magnets. The resulting optimization\ncondition reveals that improving local performance requires structurally\nmodulating the spectrum of the configuration space metric to counteract its\ndistortion. Closed-form solutions for optimal magnet configurations are derived\nunder representative conditions, and a gradient-based numerical method is\nproposed for general design scenarios. Simulation studies validate the\neffectiveness of the proposed framework."}
{"id": "2507.11447", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.11447", "abs": "https://arxiv.org/abs/2507.11447", "authors": ["Shuo Yang", "John Z. Zhang", "Ibrahima Sory Sow", "Zachary Manchester"], "title": "Multi-IMU Sensor Fusion for Legged Robots", "comment": "16 pages", "summary": "This paper presents a state-estimation solution for legged robots that uses a\nset of low-cost, compact, and lightweight sensors to achieve low-drift pose and\nvelocity estimation under challenging locomotion conditions. The key idea is to\nleverage multiple inertial measurement units on different links of the robot to\ncorrect a major error source in standard proprioceptive odometry. We fuse the\ninertial sensor information and joint encoder measurements in an extended\nKalman filter, then combine the velocity estimate from this filter with camera\ndata in a factor-graph-based sliding-window estimator to form a\nvisual-inertial-leg odometry method. We validate our state estimator through\ncomprehensive theoretical analysis and hardware experiments performed using\nreal-world robot data collected during a variety of challenging locomotion\ntasks. Our algorithm consistently achieves minimal position deviation, even in\nscenarios involving substantial ground impact, foot slippage, and sudden body\nrotations. A C++ implementation, along with a large-scale dataset, is available\nat https://github.com/ShuoYangRobotics/Cerberus2.0."}
{"id": "2507.11489", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2507.11489", "abs": "https://arxiv.org/abs/2507.11489", "authors": ["Florian Fuchs", "Bernardo Martin-Iradi", "Francesco Corman"], "title": "Solving Integrated Periodic Railway Timetabling with Satisfiability Modulo Theories: A Scalable Approach to Routing and Vehicle Circulation", "comment": null, "summary": "This paper introduces a novel approach for jointly solving the periodic Train\nTimetabling Problem (TTP), train routing, and Vehicle Circulation Problem (VCP)\nthrough a unified optimization model. While these planning stages are\ntraditionally addressed sequentially, their interdependencies often lead to\nsuboptimal vehicle usage. We propose the VCR-PESP, an integrated formulation\nthat minimizes fleet size while ensuring feasible and infrastructure-compliant\nperiodic timetables. We present the first Satisfiability Modulo Theories\n(SMT)-based method for the VCR-PESP to solve the resulting large-scale\ninstances. Unlike the Boolean Satisfiability Problem (SAT), which requires time\ndiscretisation, SMT supports continuous time via difference constraints,\neliminating the trade-off between temporal precision and encoding size. Our\napproach avoids rounding artifacts and scales effectively, outperforming both\nSAT and Mixed Integer Program (MIP) models across non-trivial instances. Using\nreal-world data from the Swiss narrow-gauge operator RhB, we conduct extensive\nexperiments to assess the impact of time discretisation, vehicle circulation\nstrategies, route flexibility, and planning integration. We show that discrete\nmodels inflate vehicle requirements and that fully integrated solutions\nsubstantially reduce fleet needs compared to sequential approaches. Our\nframework consistently delivers high-resolution solutions with tractable\nruntimes, even in large and complex networks. By combining modeling accuracy\nwith scalable solver technology, this work establishes SMT as a powerful tool\nfor integrated railway planning. It demonstrates how relaxing discretisation\nand solving across planning layers enables more efficient and implementable\ntimetables."}
{"id": "2507.10960", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.10960", "abs": "https://arxiv.org/abs/2507.10960", "authors": ["He Zhu", "Ryo Miyoshi", "Yuki Okafuji"], "title": "Whom to Respond To? A Transformer-Based Model for Multi-Party Social Robot Interaction", "comment": null, "summary": "Prior human-robot interaction (HRI) research has primarily focused on\nsingle-user interactions, where robots do not need to consider the timing or\nrecipient of their responses. However, in multi-party interactions, such as at\nmalls and hospitals, social robots must understand the context and decide both\nwhen and to whom they should respond. In this paper, we propose a\nTransformer-based multi-task learning framework to improve the decision-making\nprocess of social robots, particularly in multi-user environments. Considering\nthe characteristics of HRI, we propose two novel loss functions: one that\nenforces constraints on active speakers to improve scene modeling, and another\nthat guides response selection towards utterances specifically directed at the\nrobot. Additionally, we construct a novel multi-party HRI dataset that captures\nreal-world complexities, such as gaze misalignment. Experimental results\ndemonstrate that our model achieves state-of-the-art performance in respond\ndecisions, outperforming existing heuristic-based and single-task approaches.\nOur findings contribute to the development of socially intelligent social\nrobots capable of engaging in natural and context-aware multi-party\ninteractions."}
{"id": "2507.11513", "categories": ["math.OC", "cs.AI", "cs.NA", "math.NA", "49K20, 65M55, 65Y20, 68Q25, 68T05, 90C26, 90C30", "F.2.1; G.1.8; I.2.5"], "pdf": "https://arxiv.org/pdf/2507.11513", "abs": "https://arxiv.org/abs/2507.11513", "authors": ["Serge Gratton", "Alena Kopaničáková", "Philippe Toint"], "title": "Recursive Bound-Constrained AdaGrad with Applications to Multilevel and Domain Decomposition Minimization", "comment": "33 pages", "summary": "Two OFFO (Objective-Function Free Optimization) noise tolerant algorithms are\npresented that handle bound constraints, inexact gradients and use second-order\ninformation when available.The first is a multi-level method exploiting a\nhierarchical description of the problem and the second is a\ndomain-decomposition method covering the standard addditive Schwarz\ndecompositions. Both are generalizations of the first-order AdaGrad algorithm\nfor unconstrained optimization. Because these algorithms share a common\ntheoretical framework, a single convergence/complexity theory is provided which\ncovers them both. Its main result is that, with high probability, both methods\nneed at most $O(\\epsilon^{-2})$ iterations and noisy gradient evaluations to\ncompute an $\\epsilon$-approximate first-order critical point of the\nbound-constrained problem. Extensive numerical experiments are discussed on\napplications ranging from PDE-based problems to deep neural network training,\nillustrating their remarkable computational efficiency."}
{"id": "2507.10961", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.10961", "abs": "https://arxiv.org/abs/2507.10961", "authors": ["Joohwan Seo", "Arvind Kruthiventy", "Soomi Lee", "Megan Teng", "Xiang Zhang", "Seoyeon Choi", "Jongeun Choi", "Roberto Horowitz"], "title": "EquiContact: A Hierarchical SE(3) Vision-to-Force Equivariant Policy for Spatially Generalizable Contact-rich Tasks", "comment": "Submitted to RA-L", "summary": "This paper presents a framework for learning vision-based robotic policies\nfor contact-rich manipulation tasks that generalize spatially across task\nconfigurations. We focus on achieving robust spatial generalization of the\npolicy for the peg-in-hole (PiH) task trained from a small number of\ndemonstrations. We propose EquiContact, a hierarchical policy composed of a\nhigh-level vision planner (Diffusion Equivariant Descriptor Field, Diff-EDF)\nand a novel low-level compliant visuomotor policy (Geometric Compliant ACT,\nG-CompACT). G-CompACT operates using only localized observations (geometrically\nconsistent error vectors (GCEV), force-torque readings, and wrist-mounted RGB\nimages) and produces actions defined in the end-effector frame. Through these\ndesign choices, we show that the entire EquiContact pipeline is\nSE(3)-equivariant, from perception to force control. We also outline three key\ncomponents for spatially generalizable contact-rich policies: compliance,\nlocalized policies, and induced equivariance. Real-world experiments on PiH\ntasks demonstrate a near-perfect success rate and robust generalization to\nunseen spatial configurations, validating the proposed framework and\nprinciples. The experimental videos can be found on the project website:\nhttps://sites.google.com/berkeley.edu/equicontact"}
{"id": "2507.10968", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.10968", "abs": "https://arxiv.org/abs/2507.10968", "authors": ["Toktam Mohammadnejad", "Jovin D'sa", "Behdad Chalaki", "Hossein Nourkhiz Mahjoub", "Ehsan Moradi-Pari"], "title": "SMART-Merge Planner: A Safe Merging and Real-Time Motion Planner for Autonomous Highway On-Ramp Merging", "comment": "Accepted at IEEE ITSC 2025", "summary": "Merging onto a highway is a complex driving task that requires identifying a\nsafe gap, adjusting speed, often interactions to create a merging gap, and\ncompleting the merge maneuver within a limited time window while maintaining\nsafety and driving comfort. In this paper, we introduce a Safe Merging and\nReal-Time Merge (SMART-Merge) planner, a lattice-based motion planner designed\nto facilitate safe and comfortable forced merging. By deliberately adapting\ncost terms to the unique challenges of forced merging and introducing a desired\nspeed heuristic, SMART-Merge planner enables the ego vehicle to merge\nsuccessfully while minimizing the merge time. We verify the efficiency and\neffectiveness of the proposed merge planner through high-fidelity CarMaker\nsimulations on hundreds of highway merge scenarios. Our proposed planner\nachieves the success rate of 100% as well as completes the merge maneuver in\nthe shortest amount of time compared with the baselines, demonstrating our\nplanner's capability to handle complex forced merge tasks and provide a\nreliable and robust solution for autonomous highway merge. The simulation\nresult videos are available at\nhttps://sites.google.com/view/smart-merge-planner/home."}
{"id": "2507.10991", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.10991", "abs": "https://arxiv.org/abs/2507.10991", "authors": ["Abhimanyu Bhowmik", "Mohit Singh", "Madhushree Sannigrahi", "Martin Ludvigsen", "Kostas Alexis"], "title": "Uncertainty Aware Mapping for Vision-Based Underwater Robots", "comment": "Presented at the 2025 IEEE ICRA Workshop on Field Robotics", "summary": "Vision-based underwater robots can be useful in inspecting and exploring\nconfined spaces where traditional sensors and preplanned paths cannot be\nfollowed. Sensor noise and situational change can cause significant uncertainty\nin environmental representation. Thus, this paper explores how to represent\nmapping inconsistency in vision-based sensing and incorporate depth estimation\nconfidence into the mapping framework. The scene depth and the confidence are\nestimated using the RAFT-Stereo model and are integrated into a voxel-based\nmapping framework, Voxblox. Improvements in the existing Voxblox weight\ncalculation and update mechanism are also proposed. Finally, a qualitative\nanalysis of the proposed method is performed in a confined pool and in a pier\nin the Trondheim fjord. Experiments using an underwater robot demonstrated the\nchange in uncertainty in the visualization."}
{"id": "2507.11000", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.11000", "abs": "https://arxiv.org/abs/2507.11000", "authors": ["Minwoo Cho", "Jaehwi Jang", "Daehyung Park"], "title": "ILCL: Inverse Logic-Constraint Learning from Temporally Constrained Demonstrations", "comment": "8 pages, 6 figures", "summary": "We aim to solve the problem of temporal-constraint learning from\ndemonstrations to reproduce demonstration-like logic-constrained behaviors.\nLearning logic constraints is challenging due to the combinatorially large\nspace of possible specifications and the ill-posed nature of non-Markovian\nconstraints. To figure it out, we introduce a novel temporal-constraint\nlearning method, which we call inverse logic-constraint learning (ILCL). Our\nmethod frames ICL as a two-player zero-sum game between 1) a genetic\nalgorithm-based temporal-logic mining (GA-TL-Mining) and 2) logic-constrained\nreinforcement learning (Logic-CRL). GA-TL-Mining efficiently constructs syntax\ntrees for parameterized truncated linear temporal logic (TLTL) without\npredefined templates. Subsequently, Logic-CRL finds a policy that maximizes\ntask rewards under the constructed TLTL constraints via a novel constraint\nredistribution scheme. Our evaluations show ILCL outperforms state-of-the-art\nbaselines in learning and transferring TL constraints on four temporally\nconstrained tasks. We also demonstrate successful transfer to real-world\npeg-in-shallow-hole tasks."}
{"id": "2507.11001", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11001", "abs": "https://arxiv.org/abs/2507.11001", "authors": ["Yanbo Wang", "Zipeng Fang", "Lei Zhao", "Weidong Chen"], "title": "Learning to Tune Like an Expert: Interpretable and Scene-Aware Navigation via MLLM Reasoning and CVAE-Based Adaptation", "comment": null, "summary": "Service robots are increasingly deployed in diverse and dynamic environments,\nwhere both physical layouts and social contexts change over time and across\nlocations. In these unstructured settings, conventional navigation systems that\nrely on fixed parameters often fail to generalize across scenarios, resulting\nin degraded performance and reduced social acceptance. Although recent\napproaches have leveraged reinforcement learning to enhance traditional\nplanners, these methods often fail in real-world deployments due to poor\ngeneralization and limited simulation diversity, which hampers effective\nsim-to-real transfer. To tackle these issues, we present LE-Nav, an\ninterpretable and scene-aware navigation framework that leverages multi-modal\nlarge language model reasoning and conditional variational autoencoders to\nadaptively tune planner hyperparameters. To achieve zero-shot scene\nunderstanding, we utilize one-shot exemplars and chain-of-thought prompting\nstrategies. Additionally, a conditional variational autoencoder captures the\nmapping between natural language instructions and navigation hyperparameters,\nenabling expert-level tuning. Experiments show that LE-Nav can generate\nhyperparameters achieving human-level tuning across diverse planners and\nscenarios. Real-world navigation trials and a user study on a smart wheelchair\nplatform demonstrate that it outperforms state-of-the-art methods on\nquantitative metrics such as success rate, efficiency, safety, and comfort,\nwhile receiving higher subjective scores for perceived safety and social\nacceptance. Code is available at https://github.com/Cavendish518/LE-Nav."}
{"id": "2507.11006", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.11006", "abs": "https://arxiv.org/abs/2507.11006", "authors": ["Ashutosh Mishra", "Shreya Santra", "Hazal Gozbasi", "Kentaro Uno", "Kazuya Yoshida"], "title": "Enhancing Autonomous Manipulator Control with Human-in-loop for Uncertain Assembly Environments", "comment": "6 pages, 7 figures. Manuscript accepted at the 2025 IEEE 21st\n  International Conference on Automation Science and Engineering (CASE 2025)", "summary": "This study presents an advanced approach to enhance robotic manipulation in\nuncertain and challenging environments, with a focus on autonomous operations\naugmented by human-in-the-loop (HITL) control for lunar missions. By\nintegrating human decision-making with autonomous robotic functions, the\nresearch improves task reliability and efficiency for space applications. The\nkey task addressed is the autonomous deployment of flexible solar panels using\nan extendable ladder-like structure and a robotic manipulator with real-time\nfeedback for precision. The manipulator relays position and force-torque data,\nenabling dynamic error detection and adaptive control during deployment. To\nmitigate the effects of sinkage, variable payload, and low-lighting conditions,\nefficient motion planning strategies are employed, supplemented by human\ncontrol that allows operators to intervene in ambiguous scenarios. Digital twin\nsimulation enhances system robustness by enabling continuous feedback,\niterative task refinement, and seamless integration with the deployment\npipeline. The system has been tested to validate its performance in simulated\nlunar conditions and ensure reliability in extreme lighting, variable terrain,\nchanging payloads, and sensor limitations."}
{"id": "2507.11069", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11069", "abs": "https://arxiv.org/abs/2507.11069", "authors": ["Jeongyun Kim", "Seunghoon Jeong", "Giseop Kim", "Myung-Hwan Jeon", "Eunji Jun", "Ayoung Kim"], "title": "TRAN-D: 2D Gaussian Splatting-based Sparse-view Transparent Object Depth Reconstruction via Physics Simulation for Scene Update", "comment": null, "summary": "Understanding the 3D geometry of transparent objects from RGB images is\nchallenging due to their inherent physical properties, such as reflection and\nrefraction. To address these difficulties, especially in scenarios with sparse\nviews and dynamic environments, we introduce TRAN-D, a novel 2D Gaussian\nSplatting-based depth reconstruction method for transparent objects. Our key\ninsight lies in separating transparent objects from the background, enabling\nfocused optimization of Gaussians corresponding to the object. We mitigate\nartifacts with an object-aware loss that places Gaussians in obscured regions,\nensuring coverage of invisible surfaces while reducing overfitting.\nFurthermore, we incorporate a physics-based simulation that refines the\nreconstruction in just a few seconds, effectively handling object removal and\nchain-reaction movement of remaining objects without the need for rescanning.\nTRAN-D is evaluated on both synthetic and real-world sequences, and it\nconsistently demonstrated robust improvements over existing GS-based\nstate-of-the-art methods. In comparison with baselines, TRAN-D reduces the mean\nabsolute error by over 39% for the synthetic TRansPose sequences. Furthermore,\ndespite being updated using only one image, TRAN-D reaches a {\\delta} < 2.5 cm\naccuracy of 48.46%, over 1.5 times that of baselines, which uses six images.\nCode and more results are available at https://jeongyun0609.github.io/TRAN-D/."}
{"id": "2507.11076", "categories": ["cs.RO", "cs.NA", "math.DG", "math.DS", "math.GR", "math.NA"], "pdf": "https://arxiv.org/pdf/2507.11076", "abs": "https://arxiv.org/abs/2507.11076", "authors": ["Andreas Mueller", "Shivesh Kumar"], "title": "Closed Form Time Derivatives of the Equations of Motion of Rigid Body Systems", "comment": null, "summary": "Derivatives of equations of motion(EOM) describing the dynamics of rigid body\nsystems are becoming increasingly relevant for the robotics community and find\nmany applications in design and control of robotic systems. Controlling robots,\nand multibody systems comprising elastic components in particular, not only\nrequires smooth trajectories but also the time derivatives of the control\nforces/torques, hence of the EOM. This paper presents the time derivatives of\nthe EOM in closed form up to second-order as an alternative formulation to the\nexisting recursive algorithms for this purpose, which provides a direct insight\ninto the structure of the derivatives. The Lie group formulation for rigid body\nsystems is used giving rise to very compact and easily parameterized equations."}
{"id": "2507.11133", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.11133", "abs": "https://arxiv.org/abs/2507.11133", "authors": ["Luca Beber", "Edoardo Lamon", "Giacomo Moretti", "Matteo Saveriano", "Luca Fambri", "Luigi Palopoli", "Daniele Fontanelli"], "title": "Force-Based Viscosity and Elasticity Measurements for Material Biomechanical Characterisation with a Collaborative Robotic Arm", "comment": null, "summary": "Diagnostic activities, such as ultrasound scans and palpation, are relatively\nlow-cost. They play a crucial role in the early detection of health problems\nand in assessing their progression. However, they are also error-prone\nactivities, which require highly skilled medical staff. The use of robotic\nsolutions can be key to decreasing the inherent subjectivity of the results and\nreducing the waiting list. For a robot to perform palpation or ultrasound\nscans, it must effectively manage physical interactions with the human body,\nwhich greatly benefits from precise estimation of the patient's tissue\nbiomechanical properties. This paper assesses the accuracy and precision of a\nrobotic system in estimating the viscoelastic parameters of various materials,\nincluding some tests on ex vivo tissues as a preliminary proof-of-concept\ndemonstration of the method's applicability to biological samples. The\nmeasurements are compared against a ground truth derived from silicone\nspecimens with different viscoelastic properties, characterised using a\nhigh-precision instrument. Experimental results show that the robotic system's\naccuracy closely matches the ground truth, increasing confidence in the\npotential use of robots for such clinical applications."}
{"id": "2507.11170", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.11170", "abs": "https://arxiv.org/abs/2507.11170", "authors": ["Giulio Giacomuzzo", "Mohamed Abdelwahab", "Marco Calì", "Alberto Dalla Libera", "Ruggero Carli"], "title": "A Robust Controller based on Gaussian Processes for Robotic Manipulators with Unknown Uncertainty", "comment": null, "summary": "In this paper, we propose a novel learning-based robust feedback\nlinearization strategy to ensure precise trajectory tracking for an important\nfamily of Lagrangian systems. We assume a nominal knowledge of the dynamics is\ngiven but no a-priori bounds on the model mismatch are available. In our\napproach, the key ingredient is the adoption of a regression framework based on\nGaussian Processes (GPR) to estimate the model mismatch. This estimate is added\nto the outer loop of a classical feedback linearization scheme based on the\nnominal knowledge available. Then, to compensate for the residual uncertainty,\nwe robustify the controller including an additional term whose size is designed\nbased on the variance provided by the GPR framework. We proved that, with high\nprobability, the proposed scheme is able to guarantee asymptotic tracking of a\ndesired trajectory. We tested numerically our strategy on a 2 degrees of\nfreedom planar robot."}
{"id": "2507.11211", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.11211", "abs": "https://arxiv.org/abs/2507.11211", "authors": ["Chen Cai", "Ernesto Dickel Saraiva", "Ya-jun Pan", "Steven Liu"], "title": "MPC-based Coarse-to-Fine Motion Planning for Robotic Object Transportation in Cluttered Environments", "comment": "10 pages, 5 figures, submitted to IEEE Robotics and Automation\n  Letters (RA-L)", "summary": "This letter presents a novel coarse-to-fine motion planning framework for\nrobotic manipulation in cluttered, unmodeled environments. The system\nintegrates a dual-camera perception setup with a B-spline-based model\npredictive control (MPC) scheme. Initially, the planner generates feasible\nglobal trajectories from partial and uncertain observations. As new visual data\nare incrementally fused, both the environment model and motion planning are\nprogressively refined. A vision-based cost function promotes target-driven\nexploration, while a refined kernel-perceptron collision detector enables\nefficient constraint updates for real-time planning. The framework accommodates\nclosed-chain kinematics and supports dynamic replanning. Experiments on a\nmulti-arm platform validate its robustness and adaptability under uncertainties\nand clutter."}
{"id": "2507.11241", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.11241", "abs": "https://arxiv.org/abs/2507.11241", "authors": ["Tobias Kern", "Leon Tolksdorf", "Christian Birkner"], "title": "Comparison of Localization Algorithms between Reduced-Scale and Real-Sized Vehicles Using Visual and Inertial Sensors", "comment": null, "summary": "Physically reduced-scale vehicles are emerging to accelerate the development\nof advanced automated driving functions. In this paper, we investigate the\neffects of scaling on self-localization accuracy with visual and\nvisual-inertial algorithms using cameras and an inertial measurement unit\n(IMU). For this purpose, ROS2-compatible visual and visual-inertial algorithms\nare selected, and datasets are chosen as a baseline for real-sized vehicles. A\ntest drive is conducted to record data of reduced-scale vehicles. We compare\nthe selected localization algorithms, OpenVINS, VINS-Fusion, and RTAB-Map, in\nterms of their pose accuracy against the ground-truth and against data from\nreal-sized vehicles. When comparing the implementation of the selected\nlocalization algorithms to real-sized vehicles, OpenVINS has the lowest average\nlocalization error. Although all selected localization algorithms have\noverlapping error ranges, OpenVINS also performs best when applied to a\nreduced-scale vehicle. When reduced-scale vehicles were compared to real-sized\nvehicles, minor differences were found in translational vehicle motion\nestimation accuracy. However, no significant differences were found when\ncomparing the estimation accuracy of rotational vehicle motion, allowing RSVRs\nto be used as testing platforms for self-localization algorithms."}
{"id": "2507.11270", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.11270", "abs": "https://arxiv.org/abs/2507.11270", "authors": ["Ting-Wei Ou", "Jia-Hao Jiang", "Guan-Lin Huang", "Kuu-Young Young"], "title": "Development of an Autonomous Mobile Robotic System for Efficient and Precise Disinfection", "comment": "Accepted to the IEEE International Conference on Systems, Man, and\n  Cybernetics (SMC) 2025", "summary": "The COVID-19 pandemic has severely affected public health, healthcare\nsystems, and daily life, especially amid resource shortages and limited\nworkers. This crisis has underscored the urgent need for automation in hospital\nenvironments, particularly disinfection, which is crucial to controlling virus\ntransmission and improving the safety of healthcare personnel and patients.\nUltraviolet (UV) light disinfection, known for its high efficiency, has been\nwidely adopted in hospital settings. However, most existing research focuses on\nmaximizing UV coverage while paying little attention to the impact of human\nactivity on virus distribution. To address this issue, we propose a mobile\nrobotic system for UV disinfection focusing on the virus hotspot. The system\nprioritizes disinfection in high-risk areas and employs an approach for\noptimized UV dosage to ensure that all surfaces receive an adequate level of UV\nexposure while significantly reducing disinfection time. It not only improves\ndisinfection efficiency but also minimizes unnecessary exposure in low-risk\nareas. In two representative hospital scenarios, our method achieves the same\ndisinfection effectiveness while reducing disinfection time by 30.7% and 31.9%,\nrespectively. The video of the experiment is available at:\nhttps://youtu.be/wHcWzOcoMPM."}
{"id": "2507.11283", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.11283", "abs": "https://arxiv.org/abs/2507.11283", "authors": ["Weiyi Liu", "Jingzehua Xu", "Guanwen Xie", "Yi Li"], "title": "Ocean Diviner: A Diffusion-Augmented Reinforcement Learning for AUV Robust Control in the Underwater Tasks", "comment": null, "summary": "This paper presents a diffusion-augmented reinforcement learning (RL)\napproach for robust autonomous underwater vehicle (AUV) control, addressing key\nchallenges in underwater trajectory planning and dynamic environment\nadaptation. The proposed method integrates three core innovations: (1) A\ndiffusion-based trajectory generation framework that produces physically\nfeasible multi-step trajectories, enhanced by a high-dimensional state encoding\nmechanism combining current observations with historical states and actions\nthrough a novel diffusion U-Net architecture, significantly improving\nlong-horizon planning. (2) A sample-efficient hybrid learning architecture that\nsynergizes diffusion-guided exploration with RL policy optimization, where the\ndiffusion model generates diverse candidate actions and the RL critic selects\noptimal actions, achieving higher exploration efficiency and policy stability\nin dynamic underwater environments. Extensive simulation experiments validating\nthe method's superior robustness and flexibility, outperforms conventional\ncontrol methods in challenging marine conditions, offering enhanced\nadaptability and reliability for AUV operations in the underwater tasks."}
{"id": "2507.11296", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.11296", "abs": "https://arxiv.org/abs/2507.11296", "authors": ["Huilin Xu", "Jian Ding", "Jiakun Xu", "Ruixiang Wang", "Jun Chen", "Jinjie Mai", "Yanwei Fu", "Bernard Ghanem", "Feng Xu", "Mohamed Elhoseiny"], "title": "Diffusion-Based Imaginative Coordination for Bimanual Manipulation", "comment": "15 pages, including 10 figures and 16 tables. Accepted at ICCV 2025", "summary": "Bimanual manipulation is crucial in robotics, enabling complex tasks in\nindustrial automation and household services. However, it poses significant\nchallenges due to the high-dimensional action space and intricate coordination\nrequirements. While video prediction has been recently studied for\nrepresentation learning and control, leveraging its ability to capture rich\ndynamic and behavioral information, its potential for enhancing bimanual\ncoordination remains underexplored. To bridge this gap, we propose a unified\ndiffusion-based framework for the joint optimization of video and action\nprediction. Specifically, we propose a multi-frame latent prediction strategy\nthat encodes future states in a compressed latent space, preserving\ntask-relevant features. Furthermore, we introduce a unidirectional attention\nmechanism where video prediction is conditioned on the action, while action\nprediction remains independent of video prediction. This design allows us to\nomit video prediction during inference, significantly enhancing efficiency.\nExperiments on two simulated benchmarks and a real-world setting demonstrate a\nsignificant improvement in the success rate over the strong baseline ACT using\nour method, achieving a \\textbf{24.9\\%} increase on ALOHA, an \\textbf{11.1\\%}\nincrease on RoboTwin, and a \\textbf{32.5\\%} increase in real-world experiments.\nOur models and code are publicly available at\nhttps://github.com/return-sleep/Diffusion_based_imaginative_Coordination."}
{"id": "2507.11302", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.11302", "abs": "https://arxiv.org/abs/2507.11302", "authors": ["Jesse J. Hagenaars", "Stein Stroobants", "Sander M. Bohte", "Guido C. H. E. De Croon"], "title": "All Eyes, no IMU: Learning Flight Attitude from Vision Alone", "comment": null, "summary": "Vision is an essential part of attitude control for many flying animals, some\nof which have no dedicated sense of gravity. Flying robots, on the other hand,\ntypically depend heavily on accelerometers and gyroscopes for attitude\nstabilization. In this work, we present the first vision-only approach to\nflight control for use in generic environments. We show that a quadrotor drone\nequipped with a downward-facing event camera can estimate its attitude and\nrotation rate from just the event stream, enabling flight control without\ninertial sensors. Our approach uses a small recurrent convolutional neural\nnetwork trained through supervised learning. Real-world flight tests\ndemonstrate that our combination of event camera and low-latency neural network\nis capable of replacing the inertial measurement unit in a traditional flight\ncontrol loop. Furthermore, we investigate the network's generalization across\ndifferent environments, and the impact of memory and different fields of view.\nWhile networks with memory and access to horizon-like visual cues achieve best\nperformance, variants with a narrower field of view achieve better relative\ngeneralization. Our work showcases vision-only flight control as a promising\ncandidate for enabling autonomous, insect-scale flying robots."}
{"id": "2507.11345", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.11345", "abs": "https://arxiv.org/abs/2507.11345", "authors": ["Oscar Lima", "Marc Vinci", "Sunandita Patra", "Sebastian Stock", "Joachim Hertzberg", "Martin Atzmueller", "Malik Ghallab", "Dana Nau", "Paolo Traverso"], "title": "Acting and Planning with Hierarchical Operational Models on a Mobile Robot: A Study with RAE+UPOM", "comment": "Accepted in ECMR 2025 conference", "summary": "Robotic task execution faces challenges due to the inconsistency between\nsymbolic planner models and the rich control structures actually running on the\nrobot. In this paper, we present the first physical deployment of an integrated\nactor-planner system that shares hierarchical operational models for both\nacting and planning, interleaving the Reactive Acting Engine (RAE) with an\nanytime UCT-like Monte Carlo planner (UPOM). We implement RAE+UPOM on a mobile\nmanipulator in a real-world deployment for an object collection task. Our\nexperiments demonstrate robust task execution under action failures and sensor\nnoise, and provide empirical insights into the interleaved acting-and-planning\ndecision making process."}
{"id": "2507.11402", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.11402", "abs": "https://arxiv.org/abs/2507.11402", "authors": ["Supun Dissanayaka", "Alexander Ferrein", "Till Hofmann", "Kosuke Nakajima", "Mario Sanz-Lopez", "Jesus Savage", "Daniel Swoboda", "Matteo Tschesche", "Wataru Uemura", "Tarik Viehmann", "Shohei Yasuda"], "title": "From Production Logistics to Smart Manufacturing: The Vision for a New RoboCup Industrial League", "comment": "RoboCup Symposium 2025", "summary": "The RoboCup Logistics League is a RoboCup competition in a smart factory\nscenario that has focused on task planning, job scheduling, and multi-agent\ncoordination. The focus on production logistics allowed teams to develop highly\ncompetitive strategies, but also meant that some recent developments in the\ncontext of smart manufacturing are not reflected in the competition, weakening\nits relevance over the years. In this paper, we describe the vision for the\nRoboCup Smart Manufacturing League, a new competition designed as a larger\nsmart manufacturing scenario, reflecting all the major aspects of a modern\nfactory. It will consist of several tracks that are initially independent but\ngradually combined into one smart manufacturing scenario. The new tracks will\ncover industrial robotics challenges such as assembly, human-robot\ncollaboration, and humanoid robotics, but also retain a focus on production\nlogistics. We expect the reenvisioned competition to be more attractive to\nnewcomers and well-tried teams, while also shifting the focus to current and\nfuture challenges of industrial robotics."}
{"id": "2507.11447", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2507.11447", "abs": "https://arxiv.org/abs/2507.11447", "authors": ["Shuo Yang", "John Z. Zhang", "Ibrahima Sory Sow", "Zachary Manchester"], "title": "Multi-IMU Sensor Fusion for Legged Robots", "comment": "16 pages", "summary": "This paper presents a state-estimation solution for legged robots that uses a\nset of low-cost, compact, and lightweight sensors to achieve low-drift pose and\nvelocity estimation under challenging locomotion conditions. The key idea is to\nleverage multiple inertial measurement units on different links of the robot to\ncorrect a major error source in standard proprioceptive odometry. We fuse the\ninertial sensor information and joint encoder measurements in an extended\nKalman filter, then combine the velocity estimate from this filter with camera\ndata in a factor-graph-based sliding-window estimator to form a\nvisual-inertial-leg odometry method. We validate our state estimator through\ncomprehensive theoretical analysis and hardware experiments performed using\nreal-world robot data collected during a variety of challenging locomotion\ntasks. Our algorithm consistently achieves minimal position deviation, even in\nscenarios involving substantial ground impact, foot slippage, and sudden body\nrotations. A C++ implementation, along with a large-scale dataset, is available\nat https://github.com/ShuoYangRobotics/Cerberus2.0."}
{"id": "2507.11460", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.11460", "abs": "https://arxiv.org/abs/2507.11460", "authors": ["Jacinto Colan", "Ana Davila", "Yutaro Yamada", "Yasuhisa Hasegawa"], "title": "Human-Robot collaboration in surgery: Advances and challenges towards autonomous surgical assistants", "comment": "Accepted at 2025 IEEE International Conference on Robot and Human\n  Interactive Communication (ROMAN)", "summary": "Human-robot collaboration in surgery represents a significant area of\nresearch, driven by the increasing capability of autonomous robotic systems to\nassist surgeons in complex procedures. This systematic review examines the\nadvancements and persistent challenges in the development of autonomous\nsurgical robotic assistants (ASARs), focusing specifically on scenarios where\nrobots provide meaningful and active support to human surgeons. Adhering to the\nPRISMA guidelines, a comprehensive literature search was conducted across the\nIEEE Xplore, Scopus, and Web of Science databases, resulting in the selection\nof 32 studies for detailed analysis. Two primary collaborative setups were\nidentified: teleoperation-based assistance and direct hands-on interaction. The\nfindings reveal a growing research emphasis on ASARs, with predominant\napplications currently in endoscope guidance, alongside emerging progress in\nautonomous tool manipulation. Several key challenges hinder wider adoption,\nincluding the alignment of robotic actions with human surgeon preferences, the\nnecessity for procedural awareness within autonomous systems, the establishment\nof seamless human-robot information exchange, and the complexities of skill\nacquisition in shared workspaces. This review synthesizes current trends,\nidentifies critical limitations, and outlines future research directions\nessential to improve the reliability, safety, and effectiveness of human-robot\ncollaboration in surgical environments."}
{"id": "2507.11464", "categories": ["cs.RO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2507.11464", "abs": "https://arxiv.org/abs/2507.11464", "authors": ["Ajay Shankar", "Keisuke Okumura", "Amanda Prorok"], "title": "LF: Online Multi-Robot Path Planning Meets Optimal Trajectory Control", "comment": "9 pages; under review for IEEE Robotics & Automation - Letters (RA-L)", "summary": "We propose a multi-robot control paradigm to solve point-to-point navigation\ntasks for a team of holonomic robots with access to the full environment\ninformation. The framework invokes two processes asynchronously at high\nfrequency: (i) a centralized, discrete, and full-horizon planner for computing\ncollision- and deadlock-free paths rapidly, leveraging recent advances in\nmulti-agent pathfinding (MAPF), and (ii) dynamics-aware, robot-wise optimal\ntrajectory controllers that ensure all robots independently follow their\nassigned paths reliably. This hierarchical shift in planning representation\nfrom (i) discrete and coupled to (ii) continuous and decoupled domains enables\nthe framework to maintain long-term scalable motion synthesis. As an\ninstantiation of this idea, we present LF, which combines a fast\nstate-of-the-art MAPF solver (LaCAM), and a robust feedback control stack\n(Freyja) for executing agile robot maneuvers. LF provides a robust and\nversatile mechanism for lifelong multi-robot navigation even under asynchronous\nand partial goal updates, and adapts to dynamic workspaces simply by quick\nreplanning. We present various multirotor and ground robot demonstrations,\nincluding the deployment of 15 real multirotors with random, consecutive target\nupdates while a person walks through the operational workspace."}
{"id": "2507.11498", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2507.11498", "abs": "https://arxiv.org/abs/2507.11498", "authors": ["Asad Ali Shahid", "Francesco Braghin", "Loris Roveda"], "title": "Robot Drummer: Learning Rhythmic Skills for Humanoid Drumming", "comment": null, "summary": "Humanoid robots have seen remarkable advances in dexterity, balance, and\nlocomotion, yet their role in expressive domains, such as music performance,\nremains largely unexplored. Musical tasks, like drumming, present unique\nchallenges, including split-second timing, rapid contacts, and multi-limb\ncoordination over pieces lasting minutes. In this paper, we introduce Robot\nDrummer, a humanoid system capable of expressive, high-precision drumming\nacross a diverse repertoire of songs. We formulate humanoid drumming as\nsequential fulfillment of timed-contacts and transform drum scores in to a\nRhythmic Contact Chain. To handle the long-horizon nature of musical\nperformance, we decompose each piece into fixed-length segments and train a\nsingle policy across all segments in parallel using reinforcement learning.\nThrough extensive experiments on over thirty popular rock, metal, and jazz\ntracks, our results demonstrate that Robot Drummer consistently achieves high\nF1 scores. The learned behaviors exhibit emergent human-like drumming\nstrategies, such as cross-arm strikes, and adaptive sticks assignments,\ndemonstrating the potential of reinforcement learning to bring humanoid robots\ninto the domain of creative musical performance. Project page:\n\\href{https://robot-drummer.github.io}{robot-drummer.github.io}"}
{"id": "2507.11525", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.11525", "abs": "https://arxiv.org/abs/2507.11525", "authors": ["Ana Davila", "Jacinto Colan", "Yasuhisa Hasegawa"], "title": "LLM-based ambiguity detection in natural language instructions for collaborative surgical robots", "comment": "Accepted at 2025 IEEE International Conference on Robot and Human\n  Interactive Communication (ROMAN)", "summary": "Ambiguity in natural language instructions poses significant risks in\nsafety-critical human-robot interaction, particularly in domains such as\nsurgery. To address this, we propose a framework that uses Large Language\nModels (LLMs) for ambiguity detection specifically designed for collaborative\nsurgical scenarios. Our method employs an ensemble of LLM evaluators, each\nconfigured with distinct prompting techniques to identify linguistic,\ncontextual, procedural, and critical ambiguities. A chain-of-thought evaluator\nis included to systematically analyze instruction structure for potential\nissues. Individual evaluator assessments are synthesized through conformal\nprediction, which yields non-conformity scores based on comparison to a labeled\ncalibration dataset. Evaluating Llama 3.2 11B and Gemma 3 12B, we observed\nclassification accuracy exceeding 60% in differentiating ambiguous from\nunambiguous surgical instructions. Our approach improves the safety and\nreliability of human-robot collaboration in surgery by offering a mechanism to\nidentify potentially ambiguous instructions before robot action."}
